{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxykkZjXmIxXYhHEf3g+PZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchaase/cVAE_autism/blob/main/code/cVAE_autism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Variational Autoencoder for the ABIDE Data Set\n",
        "\n",
        "Author - Tobias Haase"
      ],
      "metadata": {
        "id": "JrGziUQyNza-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Firstly I am importaing the necessary modules here, that I will use within the following.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2OjCHUXODgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kHlOG4l2NsXd"
      },
      "outputs": [],
      "source": [
        "import torch  # The main PyTorch library for tensor computations and neural network operations\n",
        "\n",
        "import torch.nn as nn  # Provides various neural network layers and functionalities\n",
        "import torch.nn.functional as F  # Provides functional interfaces to common operations (e.g., activation functions)\n",
        "import torch.optim as optim  # Contains various optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "import torchvision  # A PyTorch library for computer vision tasks\n",
        "import torchvision.transforms as transforms  # Provides common image transformations (e.g., resizing, normalization)\n",
        "from torchvision.transforms import ToTensor  # Transforms PIL images to tensors\n",
        "from torch.utils.data import Dataset, DataLoader  # Provides tools for creating custom datasets and data loaders\n",
        "\n",
        "import numpy as np  # NumPy library for numerical computations and array operations\n",
        "import matplotlib  # Matplotlib library for data visualization\n",
        "import matplotlib.pyplot as plt  # Matplotlib's pyplot module for creating plots\n",
        "from tqdm import tqdm  # Progress bar library for tracking iterations\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I am loading the project's data. To load the data, I am using CyberDuck, and I am loaded the already preprocessed cortical thickness data.\n",
        "\n",
        "Firstly, I need to install **CyberDuck**:\n"
      ],
      "metadata": {
        "id": "k_7TkkoWPkfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e \"deb https://s3.amazonaws.com/repo.deb.cyberduck.io stable main\" | sudo tee /etc/apt/sources.list.d/cyberduck.list > /dev/null\n",
        "!sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install duck"
      ],
      "metadata": {
        "id": "S_EPD_35JAlp",
        "outputId": "180679d3-3c1a-4f50-eacd-d42ee43c042c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.Y8VbxHDIU1/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72\n",
            "gpg: key F7FAE1F32DA69515: public key \"Cyberduck <feedback@cyberduck.io>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:5 https://s3.amazonaws.com/repo.deb.cyberduck.io stable InRelease [3,245 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 https://s3.amazonaws.com/repo.deb.cyberduck.io stable/main amd64 Packages [369 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,087 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,230 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [25.6 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,686 kB in 2s (1,613 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://s3.amazonaws.com/repo.deb.cyberduck.io/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  duck\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 88.8 MB of archives.\n",
            "After this operation, 212 MB of additional disk space will be used.\n",
            "Get:1 https://s3.amazonaws.com/repo.deb.cyberduck.io stable/main amd64 duck amd64 8.6.0.39818 [88.8 MB]\n",
            "Fetched 88.8 MB in 1s (60.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package duck.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../duck_8.6.0.39818_amd64.deb ...\n",
            "Unpacking duck (8.6.0.39818) ...\n",
            "Setting up duck (8.6.0.39818) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls ./data/anat_thickness/\n",
        "!rm -rf ./data"
      ],
      "metadata": {
        "id": "3NoZwDU4dJ41"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let's download the data that I am interested in."
      ],
      "metadata": {
        "id": "p9w42L4rUP0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./data/anat_thickness  # Creating a directory before, to avoid errors\n",
        "!mkdir -p ./data/roi_thickness\n",
        "# Code to load all participants\n",
        "# !duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/anat_thickness/*_anat_thickness.nii.gz ./data/anat_thickness\n",
        "\n",
        "# Code to load the ROIs\n",
        "!duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt ./data/roi_thickness/\n",
        "\n",
        "# Code to load the 3d volume.\n",
        "#!duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/anat_thickness/CMU_a_0050653_anat_thickness.nii.gz ./data/anat_thickness/"
      ],
      "metadata": {
        "id": "360wEpwkW9QZ",
        "outputId": "281fe3fb-77d8-498a-8826-dc83dfa31804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m\u001b[s\u001b[2K\u001b[uLogin successful…\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:48 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: dhuuxtTs9QsT3eNEvlZAcHstO9wGo+QIW40JeDnhVjRmu7icPJ0KxGza+tm3qZURPfFBjuSbsYU=\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HJ89V7VD20TGG9\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:50 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: 6Tw8WNUnZP4ItN7H98M8wXN3kReJ0qSliD9RnsX5iPc3jYS4aqfCIIwUaHijGC9g1VyFnQnvurY=\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HGEJEDA3PNGE2J\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:50 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uPrepare CMU_a_0050653_roi_thickness.txt (Overwrite)…\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt?versionId=null HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: FyaXTW5RLZDV/Rnpv7s7SWAoGc0JXROsH7iY9X8fokOn4G97m9g0yAx5n35LB/4FS2ID3ePekJk=\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HV9JT72CNQK67J\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:50 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: AtKI4CXfiYJVRDwugriH8kW3Q992yAqygBxkiSzcCoJ+jG5KVWm8XVrk9NPGRqukqBhL6FQfomA=\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HWW82N3ZP2BJ8N\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:50 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> GET /?accelerate= HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 403 Forbidden\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HTP80BQG5JZGTM\u001b[m\n",
            "\u001b[31m< x-amz-id-2: SixMZO+vOicWNoyMSB1eCqXRLYkWWdp5SQro+MDHDKva+QC6q6PBcYlndhmIH3Uk86np8YaeHGM=\u001b[m\n",
            "\u001b[31m< Content-Type: application/xml\u001b[m\n",
            "\u001b[31m< Transfer-Encoding: chunked\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uDownloading CMU_a_0050653_roi_thickness.txt…\u001b[m\n",
            "\u001b[32m> GET /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt?versionId=null HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 09:34:49 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: 3ORm/OdtubqkLY+Q0ZmF5cr0YFeqRO0N+dx9AGzeahAH5/YSyJ2N5KcrdNtPySdYY7Dthuanz24=\u001b[m\n",
            "\u001b[31m< x-amz-request-id: M0HYCQYDFAH8E94C\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 09:34:50 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uDownload complete. CMU_a_0050653_roi_thickness.txt…\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's download the file with the participant info:"
      ],
      "metadata": {
        "id": "QOmEM1rpbdES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL to download the CSV file\n",
        "csv_url = \"https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv\"  # Replace with the actual URL\n",
        "\n",
        "# Directory to store the CSV file\n",
        "data_directory = \"./data/participant_info\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(data_directory, exist_ok=True)\n",
        "\n",
        "# File path to save the CSV file\n",
        "csv_file_path = os.path.join(data_directory, \"participant_info.csv\")\n",
        "\n",
        "# Download the CSV file\n",
        "response = requests.get(csv_url)\n",
        "if response.status_code == 200:\n",
        "    with open(csv_file_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(\"CSV file downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to download the CSV file.\")\n"
      ],
      "metadata": {
        "id": "pRY_50GRbfow",
        "outputId": "e9937bc4-4a54-47c9-af72-6e08e4721311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./data/anat_thickness/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYyAKwZRbTM",
        "outputId": "7854262f-0168-4c81-f244-6c3a3ae683f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CMU_a_0050653_anat_thickness.nii.gz  CMU_a_0050653_roi_thickness.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I have two options currently, eihter I load the participants data via the 3d image and overlay an atlas manually, or I use predefined labels."
      ],
      "metadata": {
        "id": "nzGFEpf_Sm7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing your text files\n",
        "data_directory = \"./data/roi_thickness/\"\n",
        "\n",
        "# Read the participant information from the CSV file\n",
        "csv_file = \"./data/participant_info/participant_info.csv\"\n",
        "participant_info_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create dictionaries to store data and participant information for autism and non-autism participants\n",
        "data_info_dict_autism = {}\n",
        "data_info_dict_no_autism = {}\n",
        "\n",
        "# Loop through each text file\n",
        "for file_name in os.listdir(data_directory):\n",
        "    # Check if the file is a text file\n",
        "    if file_name.endswith(\"_roi_thickness.txt\"):\n",
        "        # Load the text file using pandas\n",
        "        file_path = os.path.join(data_directory, file_name)\n",
        "        df = pd.read_csv(file_path, sep='\\t', header=None)\n",
        "\n",
        "        # Extract the numerical values from the second row and remove the first entry (file name) and the second entry (sub-brick)\n",
        "        data_vector = df.iloc[1, 2:].values.astype(float)\n",
        "\n",
        "        data_length = len(data_vector)\n",
        "        print(f\"File: {file_name}, Data Length: {data_length}\")\n",
        "\n",
        "        # Extract FILE_ID from the complete file name\n",
        "        file_id = file_name.split(\"_roi_thickness.txt\")[0]\n",
        "\n",
        "        # Find the participant's information based on FILE_ID in the CSV\n",
        "        participant_row = participant_info_df.loc[participant_info_df['FILE_ID'] == file_id]\n",
        "\n",
        "        # Extract age and gender from the participant's information\n",
        "        age = participant_row['AGE_AT_SCAN'].values[0]\n",
        "        gender = participant_row['SEX'].values[0]\n",
        "        dx_group = participant_row['DX_GROUP'].values[0]\n",
        "\n",
        "        # Store the data and participant information in the appropriate dictionary based on DX_GROUP\n",
        "        if dx_group == 1:\n",
        "            data_info_dict_autism[file_id] = {\n",
        "                \"data\": data_vector,\n",
        "                \"age\": age,\n",
        "                \"gender\": gender\n",
        "            }\n",
        "        elif dx_group == 2:\n",
        "            data_info_dict_no_autism[file_id] = {\n",
        "                \"data\": data_vector,\n",
        "                \"age\": age,\n",
        "                \"gender\": gender\n",
        "            }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmBh6F8mP8S5",
        "outputId": "7bb93cfe-cf9f-47f1-f52f-4dd3038a1363"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: CMU_a_0050653_roi_thickness.txt, Data Length: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data downloaded in this way is in a 3D volume. I want to have the data as a vector. Therefore, I am doing the following:"
      ],
      "metadata": {
        "id": "Lh7uQzUwYolO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Execute when working with 3D data\n",
        "\n",
        "# Directory containing your NIfTI files\n",
        "#data_directory = \"./data/anat_thickness/\"\n",
        "\n",
        "# Read the participant information from the CSV file\n",
        "csv_file = \"./data/participant_info/participant_info.csv\"\n",
        "participant_info_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create a dictionary to store data and participant information\n",
        "#data_info_dict = {}\n",
        "\n",
        "# Loop through each NIfTI file\n",
        "for file_name in os.listdir(data_directory):\n",
        "    pass\n",
        "    # Check if the file is a NIfTI file\n",
        "    if file_name.endswith(\"_anat_thickness.nii.gz\"):\n",
        "        # Load the NIfTI file\n",
        "        nifti_img = nib.load(os.path.join(data_directory, file_name))\n",
        "\n",
        "        # Get the data as a NumPy array\n",
        "        data_array = nifti_img.get_fdata()\n",
        "        print(\"The 3D data has the shape of\" ,data_array.shape)\n",
        "        # Reshape to a single vector\n",
        "        data_vector = data_array.ravel()\n",
        "\n",
        "        # Extract FILE_ID from the complete NIfTI file name\n",
        "        file_id = file_name.split(\"_anat_thickness.nii.gz\")[0]\n",
        "\n",
        "        # Find the participant's information based on FILE_ID in the CSV\n",
        "        participant_row = participant_info_df.loc[participant_info_df['FILE_ID'] == file_id]\n",
        "\n",
        "        # Extract age and gender from the participant's information\n",
        "        age = participant_row['AGE_AT_SCAN'].values[0]\n",
        "        gender = participant_row['SEX'].values[0]\n",
        "\n",
        "        # Store the data and participant information in the dictionary\n",
        "        data_info_dict[file_id] = {\n",
        "            \"data\": data_vector,\n",
        "            \"age\": age,\n",
        "            \"gender\": gender\n",
        "        }\n"
      ],
      "metadata": {
        "id": "t1AV8ehQYwCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f40fdde-4854-4cea-d633-c67795725837"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3D data has the shape of (216, 256, 291)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if this all worked:"
      ],
      "metadata": {
        "id": "AESZ6k9heLiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store information for each category\n",
        "data_lengths = []\n",
        "ages = []\n",
        "genders = []\n",
        "\n",
        "# Loop through each FILE_ID and retrieve data and participant information\n",
        "for file_id, info in data_info_dict.items():\n",
        "    data_vector = info[\"data\"]\n",
        "    age = info[\"age\"]\n",
        "    gender = info[\"gender\"]\n",
        "\n",
        "    # Calculate and store information for each category\n",
        "    data_lengths.append(len(data_vector))\n",
        "    ages.append(age)\n",
        "    genders.append(gender)\n",
        "\n",
        "# Calculate overall statistics\n",
        "total_samples = len(data_lengths)\n",
        "average_data_length = sum(data_lengths) / total_samples\n",
        "min_data_length = min(data_lengths)\n",
        "max_data_length = max(data_lengths)\n",
        "std_data_length = np.std(data_lengths)\n",
        "average_age = sum(ages) / total_samples\n",
        "min_age = min(ages)\n",
        "max_age = max(ages)\n",
        "std_age = np.std(ages)\n",
        "male_count = genders.count(1)\n",
        "female_count = genders.count(2)\n",
        "\n",
        "# Print the statistics\n",
        "print(\"Data Statistics:\")\n",
        "print(\"Total Samples:\", total_samples)\n",
        "print(\"Average Data Length:\", average_data_length)\n",
        "print(\"Minimum Data Length:\", min_data_length)\n",
        "print(\"Maximum Data Length:\", max_data_length)\n",
        "print(\"Standard Deviation of Data Length:\", std_data_length)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Age Statistics:\")\n",
        "print(\"Average Age:\", average_age)\n",
        "print(\"Minimum Age:\", min_age)\n",
        "print(\"Maximum Age:\", max_age)\n",
        "print(\"Standard Deviation of Age:\", std_age)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Gender Counts:\")\n",
        "print(\"Male Count:\", male_count)\n",
        "print(\"Female Count:\", female_count)\n"
      ],
      "metadata": {
        "id": "z8L4eCdBeNfa",
        "outputId": "edd8feea-a9cd-43c3-e60a-a6c4408cb1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Statistics:\n",
            "Total Samples: 1\n",
            "Average Data Length: 97.0\n",
            "Minimum Data Length: 97\n",
            "Maximum Data Length: 97\n",
            "Standard Deviation of Data Length: 0.0\n",
            "\n",
            "Age Statistics:\n",
            "Average Age: 30.0\n",
            "Minimum Age: 30.0\n",
            "Maximum Age: 30.0\n",
            "Standard Deviation of Age: 0.0\n",
            "\n",
            "Gender Counts:\n",
            "Male Count: 1\n",
            "Female Count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I need to create a dataloader."
      ],
      "metadata": {
        "id": "B3Aho7KLeWWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, autism_data_info, no_autism_data_info):\n",
        "        self.autism_data_info = autism_data_info\n",
        "        self.no_autism_data_info = no_autism_data_info\n",
        "        self.autism_file_ids = list(self.autism_data_info.keys())\n",
        "        self.no_autism_file_ids = list(self.no_autism_data_info.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.autism_file_ids), len(self.no_autism_file_ids))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        autism_index = index % len(self.autism_file_ids)\n",
        "        no_autism_index = index % len(self.no_autism_file_ids)\n",
        "\n",
        "        autism_file_id = self.autism_file_ids[autism_index]\n",
        "        no_autism_file_id = self.no_autism_file_ids[no_autism_index]\n",
        "\n",
        "        autism_data = torch.tensor(self.autism_data_info[autism_file_id][\"data\"], dtype=torch.float32)\n",
        "        autism_age = torch.tensor(self.autism_data_info[autism_file_id][\"age\"], dtype=torch.float32)\n",
        "        autism_gender = torch.tensor(self.autism_data_info[autism_file_id][\"gender\"], dtype=torch.float32)\n",
        "\n",
        "        no_autism_data = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"data\"], dtype=torch.float32)\n",
        "        no_autism_age = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"age\"], dtype=torch.float32)\n",
        "        no_autism_gender = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"gender\"], dtype=torch.float32)\n",
        "\n",
        "        return (autism_data, autism_age, autism_gender), (no_autism_data, no_autism_age, no_autism_gender)\n",
        "\n",
        "# Create the combined dataset\n",
        "combined_dataset = CombinedDataset(data_info_dict_autism, data_info_dict_no_autism)\n",
        "\n",
        "# Create the dataloader\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "combined_dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=shuffle)\n"
      ],
      "metadata": {
        "id": "bC421VYyebzD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model specifications\n",
        "\n",
        "In the following I am specifiying the model. I am roughly orienting myself around a paper from Anglinkas, Hartshorne & Anzellotti (2022).\n",
        "\n",
        "### Defining utility functions\n",
        "\n",
        "Firstly, I am defining the loss function.\n",
        "The loss will be computed as the sum of the BCE-Loss, as well as the KL-divergence terms.\n",
        "\n",
        "* MSE loss: Incoming\n",
        "\n",
        "* Cross Entropy: Incoming\n",
        "\n",
        "* Kullback-Leibler divergence (Kullback & Leibler, 1951) This is a measure for the difference between two distributions. I.e. \"how much do they diverge\" from each other, how much are they different to each other. The introduction of this term into the final loss leads my model to optimize not only if the precited categories are correct and so on, but also how high the difference between the prior distribution and teh latent variables are. The prior distribution in my case is an isotropic gaussian.\n",
        "  * Why is this desirable? The latent variables and the sampling process should be somewhat controlled. This divergence regulates this.\n",
        "\n",
        "\n",
        "I have also attempted to regulate that a loss is only completed with the KL divergence from the second encoder if that encoder was used."
      ],
      "metadata": {
        "id": "NV2DSYrow9-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_loss(MSE, CE, z_mu, z_logvar, s_mu, s_logvar):\n",
        "    \"\"\"\n",
        "    This function will add the reconstruction loss (BCELoss) and the KL-Divergence.\n",
        "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    :param bce_loss: reconstruction loss\n",
        "    :param z_mu: mean from the latent vector of encoder_z\n",
        "    :param z_logvar: log variance from the latent vector of encoder_z\n",
        "    :param s_mu: mean from the latent vector of encoder_s (optional)\n",
        "    :param s_logvar: log variance from the latent vector of encoder_s (optional)\n",
        "    \"\"\"\n",
        "    mse_loss = MSE\n",
        "    cross_entropy = CE\n",
        "    KLD_z = -0.5 * torch.sum(1 + z_logvar - z_mu.pow(2) - z_logvar.exp())\n",
        "    if s_mu is not None and s_logvar is not None:\n",
        "        KLD_s = -0.5 * torch.sum(1 + s_logvar - s_mu.pow(2) - s_logvar.exp())\n",
        "        return mse_loss + KLD_z + KLD_s + cross_entropy\n",
        "    else:\n",
        "        return mse_loss + KLD_z + cross_entropy\n"
      ],
      "metadata": {
        "id": "5WsDILlQlYya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the training loop. This model is supposed to achieve multiple things:\n",
        "\n",
        "* Train the cVAE using the MSE loss.\n",
        "* Incoming.\n"
      ],
      "metadata": {
        "id": "cV4DbbobmW5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, dataset, device, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss_autism = 0.0\n",
        "    running_loss_no_autism = 0.0\n",
        "    running_age_loss = 0.0\n",
        "    running_gender_loss = 0.0\n",
        "    counter = 0\n",
        "\n",
        "    total_batches = len(dataset) // dataloader.batch_size\n",
        "\n",
        "    for i, (autism_data, no_autism_data, autism_age, autism_gender, no_autism_age, no_autism_gender) in tqdm(enumerate(dataloader), total=total_batches):\n",
        "        autism_data = autism_data.to(device)\n",
        "        no_autism_data = no_autism_data.to(device)\n",
        "\n",
        "        autism_age = autism_age.to(device)\n",
        "        autism_gender = autism_gender.to(device)\n",
        "        no_autism_age = no_autism_age.to(device)\n",
        "        no_autism_gender = no_autism_gender.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the model outputs\n",
        "        z_mean, z_log_var, s_mean, s_log_var, z_mean_no_autism, z_log_var_no_autism, reconstructed_data_autism, reconstructed_data_no_autism, class_autism_age, class_autism_gender, class_no_autism_age, class_no_autism_gender = model(autism_data, no_autism_data)\n",
        "\n",
        "        # Section for the autism images\n",
        "        bce_loss_autism = criterion(reconstructed_data_autism, autism_data)\n",
        "        loss_autism = final_loss(bce_loss_autism, z_mean, z_log_var, s_mean, s_log_var)\n",
        "        running_loss_autism += loss_autism.item()\n",
        "\n",
        "        # Section for the no_autism images\n",
        "        bce_loss_no_autism = criterion(reconstructed_data_no_autism, no_autism_data)\n",
        "        s_mean_no_autism, s_log_var_no_autism = None, None\n",
        "        loss_no_autism = final_loss(bce_loss_no_autism, z_mean_no_autism, z_log_var_no_autism, s_mean_no_autism, s_log_var_no_autism)\n",
        "        running_loss_no_autism += loss_no_autism.item()\n",
        "\n",
        "        # Calculate classifier losses for age and gender predictions\n",
        "        age_loss_autism = criterion(class_autism_age, autism_age.unsqueeze(1))\n",
        "        gender_loss_autism = criterion(class_autism_gender, autism_gender)\n",
        "\n",
        "        age_loss_no_autism = criterion(class_no_autism_age, no_autism_age.unsqueeze(1))\n",
        "        gender_loss_no_autism = criterion(class_no_autism_gender, no_autism_gender)\n",
        "\n",
        "        # Accumulate classifier losses\n",
        "        running_age_loss += (age_loss_autism.item() + age_loss_no_autism.item())\n",
        "        running_gender_loss += (gender_loss_autism.item() + gender_loss_no_autism.item())\n",
        "\n",
        "        # Total loss (you can weigh the classifier losses with appropriate coefficients if needed)\n",
        "        total_loss = loss_autism + loss_no_autism + age_loss_autism + gender_loss_autism + age_loss_no_autism + gender_loss_no_autism\n",
        "        total_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        counter += len(autism_data) + len(no_autism_data)\n",
        "\n",
        "    train_loss_autism = running_loss_autism / counter\n",
        "    train_loss_no_autism = running_loss_no_autism / counter\n",
        "    train_age_loss = running_age_loss / counter\n",
        "    train_gender_loss = running_gender_loss / counter\n",
        "\n",
        "    return train_loss_autism, train_loss_no_autism, train_age_loss, train_gender_loss\n"
      ],
      "metadata": {
        "id": "6_qe6uSIfoHK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model specification\n",
        "\n",
        "These values still need to be adapted for the current model."
      ],
      "metadata": {
        "id": "rtNUqWlK6YfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dimension =\n",
        "indermediate_dim = 128\n",
        "latent_dim = 16 # latent dimension for sampling\n",
        "\n",
        "lr = 0.001\n",
        "\n"
      ],
      "metadata": {
        "id": "1NXSPtSc6biA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I want to define the contrastive variational autoencoder. While doing so, I am defining seperate encoders, to make it easier to later introduce other encoders. I am orienting myself on an cVAE I have written in the past.\n",
        "\n",
        "As the paper from Aglinskas, Hartshorne and Anzellotti (2022) I mentioned, the network will have only a few layers.\n",
        "\n",
        "A few things I will probably have to change - I do not know how many channels the data will end up having. therefore I am using one, assuming it only has one."
      ],
      "metadata": {
        "id": "yzEoxSr08h-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderNS(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(EncoderNS, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dimension, input_dimension // 8)\n",
        "        self.linear2 = nn.Linear(input_dimension // 8, input_dimension // 16)\n",
        "        self.linear3 = nn.Linear(input_dimension // 16, latent_dim)\n",
        "        self.ns_fc_mean = nn.Linear(latent_dim, latent_dim)\n",
        "        self.ns_fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, batch_size):\n",
        "        h = F.relu(self.linear1(x))\n",
        "        h = F.relu(self.linear2(h))\n",
        "        h = F.relu(self.linear3(h))\n",
        "        ns_mean = self.ns_fc_mean(h)\n",
        "        ns_log_var = self.ns_fc_log_var(h)\n",
        "        return ns_mean, ns_log_var\n",
        "\n",
        "\n",
        "class EncoderS(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(EncoderS, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dimension, input_dimension // 8)\n",
        "        self.linear2 = nn.Linear(input_dimension // 8, input_dimension // 16)\n",
        "        self.linear3 = nn.Linear(input_dimension // 16, latent_dim)\n",
        "        self.s_fc_mean = nn.Linear(latent_dim, latent_dim)\n",
        "        self.s_fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, batch_size):\n",
        "        h = F.relu(self.linear1(x))\n",
        "        h = F.relu(self.linear2(h))\n",
        "        h = F.relu(self.linear3(h))\n",
        "        s_mean = self.s_fc_mean(h)\n",
        "        s_log_var = self.s_fc_log_var(h)\n",
        "        return s_mean, s_log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear_decoder_1 = nn.Linear(latent_dim, input_dimension // 16)\n",
        "        self.linear_decoder_2 = nn.Linear(input_dimension // 16, input_dimension // 8)\n",
        "        self.linear_decoder_3 = nn.Linear(input_dimension // 8, input_dimension)\n",
        "        self.linear_decoder_4 = nn.Linear(input_dimension, output_shape)\n",
        "\n",
        "    def forward(self, zs, batch_size):\n",
        "        h_output = F.relu(self.linear_decoder_1(s_ns))\n",
        "        h_output = F.relu(self.linear_decoder_2(h_output))\n",
        "        h_output = F.relu(self.linear_decoder_3(h_output))\n",
        "        output = self.linear_decoder_4(h_output)\n",
        "        return output\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, latent_dim, num_age_classes, num_gender_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc_age = nn.Linear(latent_dim, num_age_classes)\n",
        "        self.fc_gender = nn.Linear(latent_dim, num_gender_classes)\n",
        "\n",
        "    def forward(self, z):\n",
        "        age_prediction = self.fc_age(z)\n",
        "        gender_prediction = self.fc_gender(z)\n",
        "        return age_prediction, gender_prediction\n",
        "\n",
        "        # Implement the two layers in the same step, so predict from the same step. Sigmoid vs linear. can also test the difference?\n",
        "\n",
        "class cVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, num_age_classes, num_gender_classes):\n",
        "        super(cVAE, self).__init__()\n",
        "        self.encoder_z = EncoderZ(latent_dim)\n",
        "        self.encoder_s = EncoderS(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim)\n",
        "        self.overlay_status = None\n",
        "        self.classifier = Classifier(latent_dim, num_age_classes, num_gender_classes)\n",
        "\n",
        "    def reparameterize(self, mean, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        epsilon = torch.randn_like(std)\n",
        "        return mean + epsilon * std\n",
        "\n",
        "    def forward(self, autism, no_autism):\n",
        "        batch_size = autism.size(0)\n",
        "        z_mean, z_log_var = self.encoder_z(autism, batch_size)\n",
        "        z = self.reparameterize(z_mean, z_log_var)\n",
        "        s_mean, s_log_var = self.encoder_s(autism, batch_size)\n",
        "        s = self.reparameterize(s_mean, s_log_var)\n",
        "        zs = torch.cat([z, s], dim=1)\n",
        "\n",
        "        reconstructed_data_autism = self.decoder(zs, batch_size)\n",
        "\n",
        "        z_mean_no_autism, z_log_var_no_autism = self.encoder_z(no_autism, batch_size)\n",
        "        z_no_autism = self.reparameterize(z_mean_no_autism, z_log_var_no_autism)\n",
        "        z_empty = torch.zeros(z_no_autism.shape)\n",
        "        z_no_autism_0 = torch.cat([z_no_autism, z_empty], dim=1)\n",
        "        reconstructed_data_no_autism = self.decoder(z_no_autism_0, batch_size)\n",
        "\n",
        "        class_autism_age, class_autism_gender = self.classifier(z)  # Assuming z is the latent variable after concatenating s and z\n",
        "        class_no_autism_age, class_no_autism_gender = self.classifier(z_no_autism)  # Assuming z_no_autism is the latent variable for no_autism data\n",
        "\n",
        "        return z_mean, z_log_var, s_mean, s_log_var, z_mean_no_autism, z_log_var_no_autism, reconstructed_data_autism, reconstructed_data_no_autism, class_autism_age, class_autism_gender, class_no_autism_age, class_no_autism_gender"
      ],
      "metadata": {
        "id": "uwDJGACDj1kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally the training loop - note that I have yet to define the validation function:"
      ],
      "metadata": {
        "id": "0nl-zuw8mkeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cVAE(latent_dim=64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "classifier_criterion = nn.CrossEntropyLoss\n",
        "\n",
        "train_loss_list = []  # List to store train losses\n",
        "val_loss_list = []  # List to store validation losses\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
        "    # Train the model\n",
        "    train_loss_target, train_loss_bg = train(model, overlaid_dataloader, overlaid_dataset, device, optimizer, criterion, classifier_criterion)\n",
        "\n",
        "    # Validate the model\n",
        "    val_loss, recon_images = validate(model, overlaid_dataloader, overlaid_dataset, device, criterion, classifier_criterion)\n",
        "\n",
        "    # Appending the loss values to a list to allow for visualizations:\n",
        "\n",
        "    train_loss_list.append(train_loss_target)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "\n",
        "    # Print the losses\n",
        "    print(f\"Train Loss: {train_loss_target:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Train Loss for the background: {train_loss_bg:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "print('TRAINING COMPLETE')\n"
      ],
      "metadata": {
        "id": "cgsEpXACmj_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}