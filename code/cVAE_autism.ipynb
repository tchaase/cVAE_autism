{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEZ7BZdYSbn6x49ZBubBTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchaase/cVAE_autism/blob/main/code/cVAE_autism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Variational Autoencoder for the ABIDE Data Set\n",
        "\n",
        "Author - Tobias Haase"
      ],
      "metadata": {
        "id": "JrGziUQyNza-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Firstly I am importaing the necessary modules here, that I will use within the following.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2OjCHUXODgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kHlOG4l2NsXd"
      },
      "outputs": [],
      "source": [
        "import torch  # The main PyTorch library for tensor computations and neural network operations\n",
        "\n",
        "import torch.nn as nn  # Provides various neural network layers and functionalities\n",
        "import torch.nn.functional as F  # Provides functional interfaces to common operations (e.g., activation functions)\n",
        "import torch.optim as optim  # Contains various optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "import torchvision  # A PyTorch library for computer vision tasks\n",
        "import torchvision.transforms as transforms  # Provides common image transformations (e.g., resizing, normalization)\n",
        "from torchvision.transforms import ToTensor  # Transforms PIL images to tensors\n",
        "from torch.utils.data import Dataset, DataLoader  # Provides tools for creating custom datasets and data loaders\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np  # NumPy library for numerical computations and array operations\n",
        "import matplotlib  # Matplotlib library for data visualization\n",
        "import matplotlib.pyplot as plt  # Matplotlib's pyplot module for creating plots\n",
        "from tqdm import tqdm  # Progress bar library for tracking iterations\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "gqOfbkF5lw1I",
        "outputId": "93fda18d-873a-42af-c93f-ca3bf04464fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I am loading the project's data. To load the data, I am using CyberDuck, and I am loaded the already preprocessed cortical thickness data.\n",
        "\n",
        "Firstly, I need to install **CyberDuck**:\n"
      ],
      "metadata": {
        "id": "k_7TkkoWPkfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e \"deb https://s3.amazonaws.com/repo.deb.cyberduck.io stable main\" | sudo tee /etc/apt/sources.list.d/cyberduck.list > /dev/null\n",
        "!sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install duck"
      ],
      "metadata": {
        "id": "S_EPD_35JAlp",
        "outputId": "17d2fa5b-0f62-4e67-9237-923f5d79e7e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.Q0odrWal6P/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys FE7097963FEFBE72\n",
            "gpg: key F7FAE1F32DA69515: public key \"Cyberduck <feedback@cyberduck.io>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Hit:1 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://s3.amazonaws.com/repo.deb.cyberduck.io stable InRelease [3,245 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Get:12 https://s3.amazonaws.com/repo.deb.cyberduck.io stable/main amd64 Packages [369 B]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [805 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,229 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [969 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,088 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [25.6 kB]\n",
            "Fetched 4,459 kB in 2s (2,914 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://s3.amazonaws.com/repo.deb.cyberduck.io/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  duck\n",
            "0 upgraded, 1 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 88.8 MB of archives.\n",
            "After this operation, 212 MB of additional disk space will be used.\n",
            "Get:1 https://s3.amazonaws.com/repo.deb.cyberduck.io stable/main amd64 duck amd64 8.6.0.39818 [88.8 MB]\n",
            "Fetched 88.8 MB in 4s (22.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package duck.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../duck_8.6.0.39818_amd64.deb ...\n",
            "Unpacking duck (8.6.0.39818) ...\n",
            "Setting up duck (8.6.0.39818) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls ./data/anat_thickness/\n",
        "!rm -rf ./data"
      ],
      "metadata": {
        "id": "3NoZwDU4dJ41"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let's download the data that I am interested in."
      ],
      "metadata": {
        "id": "p9w42L4rUP0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./data/anat_thickness  # Creating a directory before, to avoid errors\n",
        "!mkdir -p ./data/roi_thickness\n",
        "# Code to load all participants\n",
        "# !duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/anat_thickness/*_anat_thickness.nii.gz ./data/anat_thickness\n",
        "\n",
        "# Code to load the ROIs\n",
        "!duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt ./data/roi_thickness/\n",
        "\n",
        "# Code to load the 3d volume.\n",
        "#!duck --username anonymous --verbose --download s3:/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/ants/anat_thickness/CMU_a_0050653_anat_thickness.nii.gz ./data/anat_thickness/"
      ],
      "metadata": {
        "id": "360wEpwkW9QZ",
        "outputId": "230666f7-8ccd-4a58-c1c1-990e6361faa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[36m\u001b[s\u001b[2K\u001b[uReading metadata of CMU_a_0050653_roi_thickness.txt…\u001b[m\r\u001b[36m\u001b[s\u001b[2K\u001b[uResolving s3.amazonaws.com…\u001b[m\r\u001b[36m\u001b[s\u001b[2K\u001b[uOpening S3 connection to s3.amazonaws.com…\u001b[m\r\u001b[36m\u001b[s\u001b[2K\u001b[uS3 connection opened…\u001b[m\r\u001b[36m\u001b[s\u001b[2K\u001b[uLogin successful…\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:46 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: aNsnIyQEU89b+CHdG4YdoAySYbANHU/DHmcTztTHM6wA2MKzz9oHb5RnSOulmnrmRhYVPXr35GHupvAAXm7u5FwvVCSXI3U4\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G5CKMJ1ZPKSA30D\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:48 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: +JqLUlIwKYl3MTyKq2kBOUL/WVsga1g6BrSex9GqAG2l+i6BIGHwbNR7dEj7aj34oTxCGy4UHi3a7KAKwVYNXAIuDh67kQOb\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G55D131T1A4S0MV\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:48 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uPrepare CMU_a_0050653_roi_thickness.txt (Overwrite)…\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt?versionId=null HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: 5iU2+xlnIy4ZTkoDC3oBCGTxS9BzwsSJYV82gkP0haJLnmfFZZc4dJ677okeKP38tJrdclfkRsmm12elbnxQ2SgDnIUHywJW\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G560HXTTCYGYAWA\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:48 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> HEAD /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: TUDfqgh4yow/ETdQ7UfAQoit34RHUcX16EAlRsTAQW2DxxtK97dQTuWKDYeyqkzrxfFuxFzWxaQ3ztu2f6vuy9hMic6Rg0ty\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G5CYGAV92CQH2XD\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:48 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[31m< Content-Length: 2082\u001b[m\n",
            "\u001b[32m> GET /?accelerate= HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 403 Forbidden\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G53EWQ1JA8WTE6P\u001b[m\n",
            "\u001b[31m< x-amz-id-2: mwFWjEoWHsOv7nG+DfQRS+QqKtrXmKA4iP3A7xar2Qy2ryk54mv5UYkumHBTWTBE3AOYcxILA76RPF5GRgZzU8i6dALEuIof\u001b[m\n",
            "\u001b[31m< Content-Type: application/xml\u001b[m\n",
            "\u001b[31m< Transfer-Encoding: chunked\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uDownloading CMU_a_0050653_roi_thickness.txt…\u001b[m\n",
            "\u001b[32m> GET /data/Projects/ABIDE_Initiative/Outputs/ants/roi_thickness/CMU_a_0050653_roi_thickness.txt?versionId=null HTTP/1.1\u001b[m\n",
            "\u001b[32m> Date: Mon, 31 Jul 2023 15:36:47 GMT\u001b[m\n",
            "\u001b[32m> Host: fcp-indi.s3.amazonaws.com:443\u001b[m\n",
            "\u001b[32m> Connection: Keep-Alive\u001b[m\n",
            "\u001b[32m> User-Agent: Cyberduck/8.6.0.39818 (Linux/5.15.109+) (amd64)\u001b[m\n",
            "\u001b[32m> Accept-Encoding: gzip,deflate\u001b[m\n",
            "\u001b[31m< HTTP/1.1 200 OK\u001b[m\n",
            "\u001b[31m< x-amz-id-2: iQOPM7ILTAgxOKf9e4Lx1wQzEEmxaFl/tX2VT540q7S4ILGKZGzMMPomjUmQK7rz/7Jei2q+zvIv0zPERMMSJ2Mb2AUv7HYl\u001b[m\n",
            "\u001b[31m< x-amz-request-id: 3G50SNSQPDWVRV5N\u001b[m\n",
            "\u001b[31m< Date: Mon, 31 Jul 2023 15:36:48 GMT\u001b[m\n",
            "\u001b[31m< Last-Modified: Mon, 17 Oct 2016 18:30:24 GMT\u001b[m\n",
            "\u001b[31m< ETag: \"f5f9858d88d004f660a43abf7c0bacc3\"\u001b[m\n",
            "\u001b[31m< x-amz-version-id: null\u001b[m\n",
            "\u001b[31m< Accept-Ranges: bytes\u001b[m\n",
            "\u001b[31m< Content-Type: text/plain\u001b[m\n",
            "\u001b[31m< Server: AmazonS3\u001b[m\n",
            "\u001b[36m\u001b[s\u001b[2K\u001b[uDownload complete. CMU_a_0050653_roi_thickness.txt…\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's download the file with the participant info:"
      ],
      "metadata": {
        "id": "QOmEM1rpbdES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL to download the CSV file\n",
        "csv_url = \"https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv\"  # Replace with the actual URL\n",
        "\n",
        "# Directory to store the CSV file\n",
        "data_directory = \"./data/participant_info\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(data_directory, exist_ok=True)\n",
        "\n",
        "# File path to save the CSV file\n",
        "csv_file_path = os.path.join(data_directory, \"participant_info.csv\")\n",
        "\n",
        "# Download the CSV file\n",
        "response = requests.get(csv_url)\n",
        "if response.status_code == 200:\n",
        "    with open(csv_file_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(\"CSV file downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to download the CSV file.\")\n"
      ],
      "metadata": {
        "id": "pRY_50GRbfow",
        "outputId": "36d071b2-e308-44b8-93fd-8ca9d82f01f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./data/anat_thickness/"
      ],
      "metadata": {
        "id": "9dYyAKwZRbTM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I have two options currently, eihter I load the participants data via the 3d image and overlay an atlas manually, or I use predefined labels."
      ],
      "metadata": {
        "id": "nzGFEpf_Sm7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing your text files\n",
        "data_directory = \"./data/roi_thickness/\"\n",
        "\n",
        "# Read the participant information from the CSV file\n",
        "csv_file = \"./data/participant_info/participant_info.csv\"\n",
        "participant_info_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create dictionaries to store data and participant information for autism and non-autism participants\n",
        "data_info_dict_autism = {}\n",
        "data_info_dict_no_autism = {}\n",
        "\n",
        "# Loop through each text file\n",
        "for file_name in os.listdir(data_directory):\n",
        "    # Check if the file is a text file\n",
        "    if file_name.endswith(\"_roi_thickness.txt\"):\n",
        "        # Load the text file using pandas\n",
        "        file_path = os.path.join(data_directory, file_name)\n",
        "        df = pd.read_csv(file_path, sep='\\t', header=None)\n",
        "\n",
        "        # Extract the numerical values from the second row and remove the first entry (file name) and the second entry (sub-brick)\n",
        "        data_vector = df.iloc[1, 2:].values.astype(float)\n",
        "\n",
        "        data_length = len(data_vector)\n",
        "        print(f\"File: {file_name}, Data Length: {data_length}\")\n",
        "\n",
        "        # Extract FILE_ID from the complete file name\n",
        "        file_id = file_name.split(\"_roi_thickness.txt\")[0]\n",
        "\n",
        "        # Find the participant's information based on FILE_ID in the CSV\n",
        "        participant_row = participant_info_df.loc[participant_info_df['FILE_ID'] == file_id]\n",
        "\n",
        "        # Extract age and gender from the participant's information\n",
        "        age = participant_row['AGE_AT_SCAN'].values[0]\n",
        "        gender = participant_row['SEX'].values[0]\n",
        "        dx_group = participant_row['DX_GROUP'].values[0]\n",
        "\n",
        "        # Store the data and participant information in the appropriate dictionary based on DX_GROUP\n",
        "        if dx_group == 1:\n",
        "            data_info_dict_autism[file_id] = {\n",
        "                \"data\": data_vector,\n",
        "                \"age\": age,\n",
        "                \"gender\": gender\n",
        "            }\n",
        "        elif dx_group == 2:\n",
        "            data_info_dict_no_autism[file_id] = {\n",
        "                \"data\": data_vector,\n",
        "                \"age\": age,\n",
        "                \"gender\": gender\n",
        "            }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmBh6F8mP8S5",
        "outputId": "ae3ef0f5-fa52-4875-848a-e3ab7267b81b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: CMU_a_0050653_roi_thickness.txt, Data Length: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_info_dict_no_autism = data_info_dict_autism"
      ],
      "metadata": {
        "id": "bhQvps9SiU8d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data downloaded in this way is in a 3D volume. I want to have the data as a vector. Therefore, I am doing the following:"
      ],
      "metadata": {
        "id": "Lh7uQzUwYolO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Execute when working with 3D data\n",
        "\n",
        "# Directory containing your NIfTI files\n",
        "#data_directory = \"./data/anat_thickness/\"\n",
        "\n",
        "# Read the participant information from the CSV file\n",
        "csv_file = \"./data/participant_info/participant_info.csv\"\n",
        "participant_info_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create a dictionary to store data and participant information\n",
        "#data_info_dict = {}\n",
        "\n",
        "# Loop through each NIfTI file\n",
        "for file_name in os.listdir(data_directory):\n",
        "    pass\n",
        "    # Check if the file is a NIfTI file\n",
        "    if file_name.endswith(\"_anat_thickness.nii.gz\"):\n",
        "        # Load the NIfTI file\n",
        "        nifti_img = nib.load(os.path.join(data_directory, file_name))\n",
        "\n",
        "        # Get the data as a NumPy array\n",
        "        data_array = nifti_img.get_fdata()\n",
        "        print(\"The 3D data has the shape of\" ,data_array.shape)\n",
        "        # Reshape to a single vector\n",
        "        data_vector = data_array.ravel()\n",
        "\n",
        "        # Extract FILE_ID from the complete NIfTI file name\n",
        "        file_id = file_name.split(\"_anat_thickness.nii.gz\")[0]\n",
        "\n",
        "        # Find the participant's information based on FILE_ID in the CSV\n",
        "        participant_row = participant_info_df.loc[participant_info_df['FILE_ID'] == file_id]\n",
        "\n",
        "        # Extract age and gender from the participant's information\n",
        "        age = participant_row['AGE_AT_SCAN'].values[0]\n",
        "        gender = participant_row['SEX'].values[0]\n",
        "\n",
        "        # Store the data and participant information in the dictionary\n",
        "        data_info_dict[file_id] = {\n",
        "            \"data\": data_vector,\n",
        "            \"age\": age,\n",
        "            \"gender\": gender\n",
        "        }\n"
      ],
      "metadata": {
        "id": "t1AV8ehQYwCh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if this all worked:"
      ],
      "metadata": {
        "id": "AESZ6k9heLiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall statistics for the autism category\n",
        "autism_data_lengths = [len(info[\"data\"]) for info in data_info_dict_autism.values()]\n",
        "total_autism_samples = len(autism_data_lengths)\n",
        "average_autism_data_length = sum(autism_data_lengths) / total_autism_samples\n",
        "min_autism_data_length = min(autism_data_lengths)\n",
        "max_autism_data_length = max(autism_data_lengths)\n",
        "std_autism_data_length = np.std(autism_data_lengths)\n",
        "autism_ages = [info[\"age\"] for info in data_info_dict_autism.values()]\n",
        "average_autism_age = sum(autism_ages) / total_autism_samples\n",
        "min_autism_age = min(autism_ages)\n",
        "max_autism_age = max(autism_ages)\n",
        "std_autism_age = np.std(autism_ages)\n",
        "autism_genders = [info[\"gender\"] for info in data_info_dict_autism.values()]\n",
        "autism_male_count = autism_genders.count(1)\n",
        "autism_female_count = autism_genders.count(2)\n",
        "\n",
        "# Calculate overall statistics for the non-autism category\n",
        "non_autism_data_lengths = [len(info[\"data\"]) for info in data_info_dict_no_autism.values()]\n",
        "total_non_autism_samples = len(non_autism_data_lengths)\n",
        "average_non_autism_data_length = sum(non_autism_data_lengths) / total_non_autism_samples\n",
        "min_non_autism_data_length = min(non_autism_data_lengths)\n",
        "max_non_autism_data_length = max(non_autism_data_lengths)\n",
        "std_non_autism_data_length = np.std(non_autism_data_lengths)\n",
        "non_autism_ages = [info[\"age\"] for info in data_info_dict_no_autism.values()]\n",
        "average_non_autism_age = sum(non_autism_ages) / total_non_autism_samples\n",
        "min_non_autism_age = min(non_autism_ages)\n",
        "max_non_autism_age = max(non_autism_ages)\n",
        "std_non_autism_age = np.std(non_autism_ages)\n",
        "non_autism_genders = [info[\"gender\"] for info in data_info_dict_no_autism.values()]\n",
        "non_autism_male_count = non_autism_genders.count(1)\n",
        "non_autism_female_count = non_autism_genders.count(2)\n",
        "\n",
        "# Print the statistics for the autism category\n",
        "print(\"Autism Data Statistics:\")\n",
        "print(\"Total Samples:\", total_autism_samples)\n",
        "print(\"Average Data Length:\", average_autism_data_length)\n",
        "print(\"Minimum Data Length:\", min_autism_data_length)\n",
        "print(\"Maximum Data Length:\", max_autism_data_length)\n",
        "print(\"Standard Deviation of Data Length:\", std_autism_data_length)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Autism Age Statistics:\")\n",
        "print(\"Average Age:\", average_autism_age)\n",
        "print(\"Minimum Age:\", min_autism_age)\n",
        "print(\"Maximum Age:\", max_autism_age)\n",
        "print(\"Standard Deviation of Age:\", std_autism_age)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Autism Gender Counts:\")\n",
        "print(\"Male Count:\", autism_male_count)\n",
        "print(\"Female Count:\", autism_female_count)\n",
        "print(\"\")\n",
        "\n",
        "# Print the statistics for the non-autism category\n",
        "print(\"Non-Autism Data Statistics:\")\n",
        "print(\"Total Samples:\", total_non_autism_samples)\n",
        "print(\"Average Data Length:\", average_non_autism_data_length)\n",
        "print(\"Minimum Data Length:\", min_non_autism_data_length)\n",
        "print(\"Maximum Data Length:\", max_non_autism_data_length)\n",
        "print(\"Standard Deviation of Data Length:\", std_non_autism_data_length)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Non-Autism Age Statistics:\")\n",
        "print(\"Average Age:\", average_non_autism_age)\n",
        "print(\"Minimum Age:\", min_non_autism_age)\n",
        "print(\"Maximum Age:\", max_non_autism_age)\n",
        "print(\"Standard Deviation of Age:\", std_non_autism_age)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Non-Autism Gender Counts:\")\n",
        "print(\"Male Count:\", non_autism_male_count)\n",
        "print(\"Female Count:\", non_autism_female_count)\n"
      ],
      "metadata": {
        "id": "z8L4eCdBeNfa",
        "outputId": "f580dce8-8e67-415e-c79b-4563dee5b635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autism Data Statistics:\n",
            "Total Samples: 1\n",
            "Average Data Length: 97.0\n",
            "Minimum Data Length: 97\n",
            "Maximum Data Length: 97\n",
            "Standard Deviation of Data Length: 0.0\n",
            "\n",
            "Autism Age Statistics:\n",
            "Average Age: 30.0\n",
            "Minimum Age: 30.0\n",
            "Maximum Age: 30.0\n",
            "Standard Deviation of Age: 0.0\n",
            "\n",
            "Autism Gender Counts:\n",
            "Male Count: 1\n",
            "Female Count: 0\n",
            "\n",
            "Non-Autism Data Statistics:\n",
            "Total Samples: 1\n",
            "Average Data Length: 97.0\n",
            "Minimum Data Length: 97\n",
            "Maximum Data Length: 97\n",
            "Standard Deviation of Data Length: 0.0\n",
            "\n",
            "Non-Autism Age Statistics:\n",
            "Average Age: 30.0\n",
            "Minimum Age: 30.0\n",
            "Maximum Age: 30.0\n",
            "Standard Deviation of Age: 0.0\n",
            "\n",
            "Non-Autism Gender Counts:\n",
            "Male Count: 1\n",
            "Female Count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I need to create a dataloader."
      ],
      "metadata": {
        "id": "B3Aho7KLeWWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, autism_data_info, no_autism_data_info):\n",
        "        self.autism_data_info = autism_data_info\n",
        "        self.no_autism_data_info = no_autism_data_info\n",
        "        self.autism_file_ids = list(self.autism_data_info.keys())\n",
        "        self.no_autism_file_ids = list(self.no_autism_data_info.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.autism_file_ids), len(self.no_autism_file_ids))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        autism_index = index % len(self.autism_file_ids)\n",
        "        no_autism_index = index % len(self.no_autism_file_ids)\n",
        "\n",
        "        autism_file_id = self.autism_file_ids[autism_index]\n",
        "        no_autism_file_id = self.no_autism_file_ids[no_autism_index]\n",
        "\n",
        "        autism_data = torch.tensor(self.autism_data_info[autism_file_id][\"data\"], dtype=torch.float32)\n",
        "        autism_age = torch.tensor(self.autism_data_info[autism_file_id][\"age\"], dtype=torch.float32)\n",
        "        autism_gender = torch.tensor(self.autism_data_info[autism_file_id][\"gender\"], dtype=torch.float32)\n",
        "\n",
        "        no_autism_data = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"data\"], dtype=torch.float32)\n",
        "        no_autism_age = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"age\"], dtype=torch.float32)\n",
        "        no_autism_gender = torch.tensor(self.no_autism_data_info[no_autism_file_id][\"gender\"], dtype=torch.float32)\n",
        "\n",
        "        return (autism_data, autism_age, autism_gender), (no_autism_data, no_autism_age, no_autism_gender)\n",
        "\n",
        "# Create the combined dataset\n",
        "combined_dataset = CombinedDataset(data_info_dict_autism, data_info_dict_no_autism)\n",
        "\n",
        "# Create the dataloader\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "combined_dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=shuffle)\n"
      ],
      "metadata": {
        "id": "bC421VYyebzD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model specifications\n",
        "\n",
        "In the following I am specifiying the model. I am roughly orienting myself around a paper from Anglinkas, Hartshorne & Anzellotti (2022).\n",
        "\n",
        "### Defining utility functions\n",
        "\n",
        "Firstly, I am defining the loss function.\n",
        "The loss will be computed as the sum of the BCE-Loss, as well as the KL-divergence terms.\n",
        "\n",
        "* MSE loss: Incoming\n",
        "\n",
        "* Cross Entropy: Incoming\n",
        "\n",
        "* Kullback-Leibler divergence (Kullback & Leibler, 1951) This is a measure for the difference between two distributions. I.e. \"how much do they diverge\" from each other, how much are they different to each other. The introduction of this term into the final loss leads my model to optimize not only if the precited categories are correct and so on, but also how high the difference between the prior distribution and teh latent variables are. The prior distribution in my case is an isotropic gaussian.\n",
        "  * Why is this desirable? The latent variables and the sampling process should be somewhat controlled. This divergence regulates this.\n",
        "\n",
        "\n",
        "I have also attempted to regulate that a loss is only completed with the KL divergence from the second encoder if that encoder was used."
      ],
      "metadata": {
        "id": "NV2DSYrow9-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_loss(MSE, CE, z_mu, z_logvar, s_mu, s_logvar):\n",
        "    \"\"\"\n",
        "    This function will add the reconstruction loss (BCELoss) and the KL-Divergence.\n",
        "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    :param bce_loss: reconstruction loss\n",
        "    :param z_mu: mean from the latent vector of encoder_z\n",
        "    :param z_logvar: log variance from the latent vector of encoder_z\n",
        "    :param s_mu: mean from the latent vector of encoder_s (optional)\n",
        "    :param s_logvar: log variance from the latent vector of encoder_s (optional)\n",
        "    \"\"\"\n",
        "    mse_loss = MSE\n",
        "    cross_entropy = CE\n",
        "    KLD_z = -0.5 * torch.sum(1 + z_logvar - z_mu.pow(2) - z_logvar.exp())\n",
        "    if s_mu is not None and s_logvar is not None:\n",
        "        KLD_s = -0.5 * torch.sum(1 + s_logvar - s_mu.pow(2) - s_logvar.exp())\n",
        "        return mse_loss + KLD_z + KLD_s + cross_entropy\n",
        "    else:\n",
        "        return mse_loss + KLD_z + cross_entropy\n"
      ],
      "metadata": {
        "id": "5WsDILlQlYya"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the training loop. This model is supposed to achieve multiple things:\n",
        "\n",
        "* Train the cVAE using the MSE loss.\n",
        "* Incoming.\n"
      ],
      "metadata": {
        "id": "cV4DbbobmW5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, dataset, device, optimizer, criterion, criterion_classifier):\n",
        "    model.train()\n",
        "    running_loss_autism = 0.0\n",
        "    running_loss_no_autism = 0.0\n",
        "    running_age_loss = 0.0\n",
        "    running_gender_loss = 0.0\n",
        "    counter = 0\n",
        "\n",
        "    total_batches = len(dataset) // dataloader.batch_size\n",
        "\n",
        "    for i, ((autism_data, autism_age, autism_gender), (no_autism_data, no_autism_age, no_autism_gender)) in tqdm(enumerate(dataloader), total=total_batches):\n",
        "        autism_data = autism_data.to(device)\n",
        "        no_autism_data = no_autism_data.to(device)\n",
        "\n",
        "        autism_age = autism_age.to(device)\n",
        "        autism_gender = autism_gender.to(device)\n",
        "        no_autism_age = no_autism_age.to(device)\n",
        "        no_autism_gender = no_autism_gender.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the model outputs\n",
        "        z_mean, z_log_var, s_mean, s_log_var, z_mean_no_autism, z_log_var_no_autism, reconstructed_data_autism, reconstructed_data_no_autism, class_autism_age, class_autism_gender, class_no_autism_age, class_no_autism_gender = model(autism_data, no_autism_data)\n",
        "\n",
        "        # Section for the autism images\n",
        "        bce_loss_autism = criterion(reconstructed_data_autism, autism_data)\n",
        "        loss_autism = final_loss(bce_loss_autism, z_mean, z_log_var, s_mean, s_log_var)\n",
        "        running_loss_autism += loss_autism.item()\n",
        "\n",
        "        # Section for the no_autism images\n",
        "        bce_loss_no_autism = criterion(reconstructed_data_no_autism, no_autism_data)\n",
        "        s_mean_no_autism, s_log_var_no_autism = None, None\n",
        "        loss_no_autism = final_loss(bce_loss_no_autism, z_mean_no_autism, z_log_var_no_autism, s_mean_no_autism, s_log_var_no_autism)\n",
        "        running_loss_no_autism += loss_no_autism.item()\n",
        "\n",
        "        # Calculate classifier losses for age and gender predictions\n",
        "        age_loss_autism = criterion_classifier(class_autism_age, autism_age.unsqueeze(1))\n",
        "        gender_loss_autism = criterion_classifier(class_autism_gender, autism_gender)\n",
        "\n",
        "        age_loss_no_autism = criterion_classifier(class_no_autism_age, no_autism_age.unsqueeze(1))\n",
        "        gender_loss_no_autism = criterion_classifier(class_no_autism_gender, no_autism_gender)\n",
        "\n",
        "        # Accumulate classifier losses\n",
        "        running_age_loss += (age_loss_autism.item() + age_loss_no_autism.item())\n",
        "        running_gender_loss += (gender_loss_autism.item() + gender_loss_no_autism.item())\n",
        "\n",
        "        # Total loss (you can weigh the classifier losses with appropriate coefficients if needed)\n",
        "        total_loss = loss_autism + loss_no_autism + age_loss_autism + gender_loss_autism + age_loss_no_autism + gender_loss_no_autism\n",
        "        total_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        counter += len(autism_data) + len(no_autism_data)\n",
        "\n",
        "    train_loss_autism = running_loss_autism / counter\n",
        "    train_loss_no_autism = running_loss_no_autism / counter\n",
        "    train_age_loss = running_age_loss / counter\n",
        "    train_gender_loss = running_gender_loss / counter\n",
        "\n",
        "    return train_loss_autism, train_loss_no_autism, train_age_loss, train_gender_loss\n"
      ],
      "metadata": {
        "id": "6_qe6uSIfoHK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model specification\n",
        "\n",
        "These values still need to be adapted for the current model."
      ],
      "metadata": {
        "id": "rtNUqWlK6YfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dimension = 97 # The numer of features\n",
        "indermediate_dim = 128\n",
        "latent_dim = 4 # latent dimension for sampling\n",
        "\n",
        "lr = 0.001\n",
        "\n"
      ],
      "metadata": {
        "id": "1NXSPtSc6biA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I want to define the contrastive variational autoencoder. While doing so, I am defining seperate encoders, to make it easier to later introduce other encoders. I am orienting myself on an cVAE I have written in the past.\n",
        "\n",
        "As the paper from Aglinskas, Hartshorne and Anzellotti (2022) I mentioned, the network will have only a few layers.\n",
        "\n",
        "A few things I will probably have to change - I do not know how many channels the data will end up having. therefore I am using one, assuming it only has one."
      ],
      "metadata": {
        "id": "yzEoxSr08h-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderNS(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(EncoderNS, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dimension, 64)\n",
        "        self.linear2 = nn.Linear(64, 32)\n",
        "        self.linear3 = nn.Linear(32, 4)\n",
        "        self.ns_fc_mean = nn.Linear(latent_dim, latent_dim)\n",
        "        self.ns_fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, batch_size):\n",
        "        h = F.relu(self.linear1(x))\n",
        "        h = F.relu(self.linear2(h))\n",
        "        h = F.relu(self.linear3(h))\n",
        "        ns_mean = self.ns_fc_mean(h)\n",
        "        ns_log_var = self.ns_fc_log_var(h)\n",
        "        return ns_mean, ns_log_var\n",
        "\n",
        "\n",
        "class EncoderS(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(EncoderS, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dimension, 64)\n",
        "        self.linear2 = nn.Linear(64, 32)\n",
        "        self.linear3 = nn.Linear(32, 4)\n",
        "        self.s_fc_mean = nn.Linear(latent_dim, latent_dim)\n",
        "        self.s_fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, batch_size):\n",
        "        h = F.relu(self.linear1(x))\n",
        "        h = F.relu(self.linear2(h))\n",
        "        h = F.relu(self.linear3(h))\n",
        "        s_mean = self.s_fc_mean(h)\n",
        "        s_log_var = self.s_fc_log_var(h)\n",
        "        return s_mean, s_log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear_decoder_1 = nn.Linear(latent_dim, 32)\n",
        "        self.linear_decoder_2 = nn.Linear(32,64)\n",
        "        self.linear_decoder_3 = nn.Linear(64, input_dimension)\n",
        "\n",
        "    def forward(self, zs, batch_size):\n",
        "        h_output = F.relu(self.linear_decoder_1(zs))\n",
        "        h_output = F.relu(self.linear_decoder_2(h_output))\n",
        "        output = F.relu(self.linear_decoder_3(h_output))\n",
        "        return output\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, latent_dim // 2)\n",
        "        self.fc_age = nn.Linear(latent_dim // 2, 1)\n",
        "        self.fc_gender = nn.Linear(latent_dim // 2, 2)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc1(z)\n",
        "        age_prediction = self.fc_age(x)\n",
        "        gender_prediction = torch.sigmoid(self.fc_gender(x))  # Apply sigmoid activation for binary gender prediction\n",
        "        return age_prediction, gender_prediction\n",
        "\n",
        "class cVAE(nn.Module):\n",
        "    def __init__(self, input_dimension, latent_dim):\n",
        "        super(cVAE, self).__init__()\n",
        "        self.encoder_z = EncoderNS(input_dimension, latent_dim)\n",
        "        self.encoder_s = EncoderS(input_dimension, latent_dim)\n",
        "        self.decoder = Decoder(input_dimension, latent_dim)\n",
        "        self.overlay_status = None\n",
        "        self.classifier = Classifier(latent_dim)\n",
        "\n",
        "    def reparameterize(self, mean, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        epsilon = torch.randn_like(std)\n",
        "        return mean + epsilon * std\n",
        "\n",
        "    def forward(self, autism, no_autism):\n",
        "        batch_size = autism.size(0)\n",
        "        z_mean, z_log_var = self.encoder_z(autism, batch_size)\n",
        "        z = self.reparameterize(z_mean, z_log_var)\n",
        "        s_mean, s_log_var = self.encoder_s(autism, batch_size)\n",
        "        s = self.reparameterize(s_mean, s_log_var)\n",
        "        zs = torch.cat([z, s], dim=1)\n",
        "\n",
        "        reconstructed_data_autism = self.decoder(zs, batch_size)\n",
        "\n",
        "        z_mean_no_autism, z_log_var_no_autism = self.encoder_z(no_autism, batch_size)\n",
        "        z_no_autism = self.reparameterize(z_mean_no_autism, z_log_var_no_autism)\n",
        "        z_empty = torch.zeros(z_no_autism.shape)\n",
        "        z_no_autism_0 = torch.cat([z_no_autism, z_empty], dim=1)\n",
        "        reconstructed_data_no_autism = self.decoder(z_no_autism_0, batch_size)\n",
        "\n",
        "        class_autism_age, class_autism_gender = self.classifier(z)  # Assuming z is the latent variable after concatenating s and z\n",
        "        class_no_autism_age, class_no_autism_gender = self.classifier(z_no_autism_0)  # Using the version with 0s to have equal lengths of the latent vectors.\n",
        "\n",
        "        return z_mean, z_log_var, s_mean, s_log_var, z_mean_no_autism, z_log_var_no_autism, reconstructed_data_autism, reconstructed_data_no_autism, class_autism_age, class_autism_gender, class_no_autism_age, class_no_autism_gender"
      ],
      "metadata": {
        "id": "uwDJGACDj1kR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally the training loop - note that I have yet to define the validation function:"
      ],
      "metadata": {
        "id": "0nl-zuw8mkeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "++++model = cVAE(input_dimension = 97, latent_dim=4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "classifier_criterion = nn.CrossEntropyLoss\n",
        "\n",
        "train_loss_list = []  # List to store train losses\n",
        "val_loss_list = []  # List to store validation losses\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
        "    # Train the model\n",
        "    train_loss_target, train_loss_bg = train(model, combined_dataloader,combined_dataset, device, optimizer, criterion, classifier_criterion)\n",
        "\n",
        "    # Validate the model\n",
        "    #val_loss, recon_images = validate(model, overlaid_dataloader, overlaid_dataset, device, criterion, classifier_criterion)\n",
        "\n",
        "    # Appending the loss values to a list to allow for visualizations:\n",
        "\n",
        "    train_loss_list.append(train_loss_target)\n",
        "    #val_loss_list.append(val_loss)\n",
        "\n",
        "\n",
        "    # Print the losses\n",
        "    print(f\"Train Loss: {train_loss_target:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "    #print(f\"Train Loss for the background: {train_loss_bg:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "print('TRAINING COMPLETE')\n"
      ],
      "metadata": {
        "id": "cgsEpXACmj_H",
        "outputId": "7c5d70bc-21f1-4754-ced0-4d6a8ce77db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f7d59f5d8b0f>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombined_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-3f919ffd80af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, dataset, device, optimizer, criterion, criterion_classifier)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Get the model outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_log_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean_no_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var_no_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_data_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_data_no_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_autism_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_autism_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_no_autism_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_no_autism_gender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautism_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_autism_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Section for the autism images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e5d3b18f9ffd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, autism, no_autism)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mreconstructed_data_autism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mz_mean_no_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var_no_autism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_autism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-e5d3b18f9ffd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, zs, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mh_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_decoder_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mh_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_decoder_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_decoder_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x8 and 4x32)"
          ]
        }
      ]
    }
  ]
}